{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb1c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7862/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7faa2c222700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x7faa2b07bb80>,\n",
       " 'http://127.0.0.1:7862/',\n",
       " None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_url, hf_hub_download\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path_to_model = hf_hub_download(repo_id=\"opetrova/face-frontalization\", filename=\"generator_v0.pt\")\n",
    "\n",
    "# Download network.py into the current directory\n",
    "network_url = hf_hub_url(repo_id=\"opetrova/face-frontalization\", filename=\"network.py\")\n",
    "r = requests.get(network_url, allow_redirects=True)\n",
    "open('network.py', 'wb').write(r.content)\n",
    "\n",
    "saved_model = torch.load(path_to_model, map_location=torch.device('cpu'))\n",
    "\n",
    "def frontalize(image):\n",
    "    \n",
    "    # Convert the test image to a [1, 3, 128, 128]-shaped torch tensor\n",
    "    # (as required by the frontalization model)\n",
    "    preprocess = transforms.Compose((transforms.ToPILImage(), \n",
    "                                     transforms.Resize(size = (128, 128)), \n",
    "                                     transforms.ToTensor()))\n",
    "    input_tensor = torch.unsqueeze(preprocess(image), 0)\n",
    "    \n",
    "    # Use the saved model to generate an output (whose values go between -1 and 1, \n",
    "    # and this will need to get fixed before the output is displayed)\n",
    "    generated_image = saved_model(Variable(input_tensor.type('torch.FloatTensor')))\n",
    "    generated_image = generated_image.detach().squeeze().permute(1, 2, 0).numpy()\n",
    "    generated_image = (generated_image + 1.0) / 2.0\n",
    "    \n",
    "    return generated_image\n",
    "\n",
    "iface = gr.Interface(frontalize, gr.inputs.Image(type=\"numpy\"), \"image\")\n",
    "iface.launch()                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
